{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "from dtaidistance import dtw\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_index(timeend: np.datetime64, window_size: int) -> pd.DatetimeIndex:\n",
    "    freq = '10min'\n",
    "    return pd.date_range(end=timeend, periods=window_size, freq=freq)\n",
    "\n",
    "def safe_nansum(arr, axis=None):\n",
    "    result = np.nansum(arr, axis=axis)\n",
    "    # 判斷原始陣列沿 axis 全部是 NaN 的位置\n",
    "    all_nan = np.isnan(arr).all(axis=axis)\n",
    "    \n",
    "    # 將那些位置改為 np.nan\n",
    "    if np.isscalar(result):\n",
    "        return np.nan if all_nan else result\n",
    "    result = result.astype('float64')  # 確保能裝 NaN\n",
    "    result[all_nan] = np.nan\n",
    "    return result\n",
    "\n",
    "def generate_valid_subsequences(arr, min_len=1, max_len=None):\n",
    "    max_len = len(arr) if max_len is None else max_len\n",
    "    \n",
    "    subsequences = []\n",
    "    N = len(arr)\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(i + min_len, min(i + max_len, N) + 1):\n",
    "            subseq = arr[i:j]\n",
    "            if not np.isnan(subseq[0]) and not np.isnan(subseq[-1]):\n",
    "                subsequences.append(subseq)\n",
    "    \n",
    "    return subsequences\n",
    "\n",
    "def expand_to_all_right_shifts(seq, target_len=24):\n",
    "    seq = np.asarray(seq)\n",
    "    L = len(seq)\n",
    "    assert L <= target_len, \"序列長度不能超過 24\"\n",
    "    expanded_versions = []\n",
    "    for shift in range(target_len - L + 1):\n",
    "        left = np.full(shift, np.nan)\n",
    "        right = np.full(target_len - L - shift, np.nan)\n",
    "        padded = np.concatenate([left, seq, right])\n",
    "        expanded_versions.append(padded)\n",
    "    return expanded_versions\n",
    "\n",
    "def expand_all_sequences(seq_list, target_len=24):\n",
    "    all_expanded = []\n",
    "    for seq in seq_list:\n",
    "        expanded = expand_to_all_right_shifts(seq, target_len)\n",
    "        all_expanded.extend(expanded)\n",
    "    return np.array(all_expanded)  # shape: (total, 24)\n",
    "\n",
    "def fast_dtw_distance(ref, compare_arr):\n",
    "    if len(compare_arr.shape) == 2:\n",
    "        distances = np.empty(compare_arr.shape[0])\n",
    "        for i in range(compare_arr.shape[0]):\n",
    "            mask = ~np.isnan(compare_arr[i])\n",
    "            distances[i] = dtw.distance(ref[mask], compare_arr[i][mask])\n",
    "    else:\n",
    "        mask = ~np.isnan(compare_arr)\n",
    "        distances = dtw.distance(ref[mask], compare_arr[mask])\n",
    "    return distances\n",
    "def kde_logpdf_weighted(X_query, X_sample, weights, bandwidth):\n",
    "    \"\"\"\n",
    "    使用加權 KDE（Gaussian）估計 log pdf\n",
    "    \"\"\"\n",
    "    d2 = cdist(X_query, X_sample, metric='sqeuclidean')  # shape (Q, N)\n",
    "    kernel_vals = np.exp(-d2 / (2 * bandwidth**2))\n",
    "    weighted_kernels = kernel_vals * weights[None, :]  # broadcasting\n",
    "    density = np.sum(weighted_kernels, axis=1) + 1e-12  # 避免除 0\n",
    "    norm = (1 / (np.sqrt(2 * np.pi) * bandwidth))**X_sample.shape[1]\n",
    "    return np.log(norm * density)\n",
    "\n",
    "def compute_posterior_weights_from_partial_subseq(\n",
    "    X_joint,               # (N, t): joint samples\n",
    "    w_prior,               # (N, ): prior weights\n",
    "    X_marginal_obs,        # (M, m): observed marginal with NaNs allowed\n",
    "    w_obs,                 # (M, ): obs weights\n",
    "    # observed_dims,         # (k, ): indices of observed dimensions (e.g., [0,2])\n",
    "    bandwidth=0.5\n",
    "):\n",
    "    # 驗證\n",
    "    N, t = X_joint.shape\n",
    "    M, m = X_marginal_obs.shape\n",
    "    observed_dims = np.where(~np.isnan(X_marginal_obs[0]))[0]\n",
    "    assert len(w_prior) == N, \"w_prior 長度錯誤\"\n",
    "    assert len(w_obs) == M, \"w_obs 長度錯誤\"\n",
    "\n",
    "    # Normalize weights\n",
    "    w_prior = w_prior / np.sum(w_prior)\n",
    "    w_obs = w_obs / np.sum(w_obs)\n",
    "\n",
    "    # 萃取有效維度\n",
    "    X_joint_sub = X_joint[:, observed_dims]                # shape (N, k)\n",
    "    X_obs_sub = X_marginal_obs[:, observed_dims]           # shape (M, k)\n",
    "\n",
    "    # KDE\n",
    "    log_p_obs = kde_logpdf_weighted(X_joint_sub, X_obs_sub, w_obs, bandwidth)\n",
    "    log_p_prior = kde_logpdf_weighted(X_joint_sub, X_joint_sub, w_prior, bandwidth)\n",
    "\n",
    "    # 計算後驗權重\n",
    "    log_w_post = log_p_obs - log_p_prior + np.log(w_prior + 1e-10)\n",
    "    w_post = np.exp(log_w_post)\n",
    "    w_post /= np.sum(w_post)\n",
    "\n",
    "    return w_post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tdf = pd.DataFrame()\n",
    "for i in range(0,40):\n",
    "    try:\n",
    "        df = pd.read_csv(f'../data/Raw_Data/Gogoro/台北市大安區_臺大二活停車場站A ({i:02d}).csv',index_col=0)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df.index = df.index.floor('min')\n",
    "        df = df[~df.index.duplicated()]\n",
    "        a_tdf = pd.concat([a_tdf,df])\n",
    "    except:\n",
    "        continue\n",
    "a_tdf = a_tdf[~a_tdf.index.duplicated()]\n",
    "a_tdf.sort_index(inplace=True)\n",
    "\n",
    "b_tdf = pd.DataFrame()\n",
    "for i in range(0,37):\n",
    "    try:\n",
    "        df = pd.read_csv(f'../data/Raw_Data/Gogoro/台北市大安區_臺大二活停車場站B ({i:02d}).csv',index_col=0)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df.index = df.index.floor('min')\n",
    "        df = df[~df.index.duplicated()]\n",
    "        b_tdf = pd.concat([b_tdf,df])\n",
    "    except:\n",
    "        continue\n",
    "b_tdf = b_tdf[~b_tdf.index.duplicated()]\n",
    "b_tdf.sort_index(inplace=True)\n",
    "\n",
    "tdf = pd.concat([a_tdf,b_tdf],axis=1).dropna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假設 df 已經處理好 index 是 datetime 且只保留到分鐘\n",
    "start = tdf.index.min()\n",
    "end = tdf.index.max()\n",
    "\n",
    "# 產生每分鐘的完整時間序列\n",
    "full_index = pd.date_range(start=start, end=end, freq='1min')\n",
    "\n",
    "# 將原始 df 補上缺的時間，空值保持為 NaN\n",
    "tdf_filled = tdf.reindex(full_index)\n",
    "\n",
    "tdf_filled = tdf_filled.resample('h').mean()\n",
    "tdf_filled.name = 'raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 24\n",
    "subseqs = generate_valid_subsequences(tdf_filled.values, min_len=2, max_len=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "subseqs = expand_all_sequences(subseqs,target_len=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算 mean 與 std\n",
    "mean = np.nanmean(subseqs, axis=1, keepdims=True)\n",
    "std = np.nanstd(subseqs, axis=1, keepdims=True)\n",
    "\n",
    "# 建立空白陣列\n",
    "z_scaled = np.full_like(subseqs, np.nan)\n",
    "\n",
    "# 標準差 ≠ 0 的 row\n",
    "valid_rows = ((std != 0) & ~np.isnan(std))[:, 0]\n",
    "z_scaled[valid_rows] = (subseqs[valid_rows] - mean[valid_rows]) / std[valid_rows]\n",
    "\n",
    "# 標準差 = 0 的 row\n",
    "const_rows = ((std == 0) & ~np.isnan(std))[:, 0]\n",
    "z_scaled[const_rows] = np.where(\n",
    "    ~np.isnan(subseqs[const_rows]),\n",
    "    0.0,\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# 回存\n",
    "subseqs = z_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_samples = defaultdict(list)\n",
    "\n",
    "for i,row in enumerate(subseqs):\n",
    "    not_nan_indices = np.where(~np.isnan(row))[0]\n",
    "    if len(not_nan_indices) == 0:\n",
    "        continue  # 跳過全 NaN 的 row\n",
    "\n",
    "    # 觀測的位置（相對於 trimmed）\n",
    "    observed = tuple(np.where(~np.isnan(row))[0])\n",
    "    grouped_samples[observed].append(row)\n",
    "    \n",
    "sorted_items = sorted(grouped_samples.items(), key=lambda x: len(x[0]), reverse=True)\n",
    "grouped_samples = dict(sorted_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前 3 小時上升\n",
    "up = np.linspace(10, 21, 3)  # 從 10 上升到 21，共 3 點\n",
    "\n",
    "# 後 21 小時下降（從 21 下降到 0）\n",
    "down = np.linspace(21, 0, 24 - 3)\n",
    "\n",
    "# 合併成一條完整曲線\n",
    "curve = np.concatenate([up, down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.normal(loc=46, scale=40, size=window_size)\n",
    "seed = np.linspace(0, 10, window_size)\n",
    "seed = curve*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_seed(seed):\n",
    "    mean_val = np.mean(seed)\n",
    "    std_val = np.std(seed)\n",
    "\n",
    "    if np.allclose(seed, seed[0]):\n",
    "        # 常數列 → mean scaling\n",
    "        if mean_val != 0:\n",
    "            normal = seed / mean_val\n",
    "        else:\n",
    "            normal = np.zeros_like(seed)\n",
    "    else:\n",
    "        # 一般情況 → Z-score\n",
    "        if std_val != 0:\n",
    "            normal = (seed - mean_val) / std_val\n",
    "        else:\n",
    "            normal = np.zeros_like(seed)  # 極端情況保險處理\n",
    "\n",
    "    return mean_val, std_val, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_seed,std_seed,normal_seed = normalize_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406, 24)\n"
     ]
    }
   ],
   "source": [
    "key = list(grouped_samples.keys())[0]\n",
    "\n",
    "p_weighted = defaultdict(float)\n",
    "history = np.array(grouped_samples[key])\n",
    "\n",
    "print(pd.DataFrame(history).dropna(axis=1).shape)\n",
    "\n",
    "distances = fast_dtw_distance(normal_seed, history)\n",
    "weights = 1/distances**2\n",
    "for row, weight in zip(history, weights):\n",
    "    key = tuple(row[~np.isnan(row)])  # 觀測的變數組合\n",
    "    p_weighted[key] += weight\n",
    "total = sum(p_weighted.values())\n",
    "for k in p_weighted:\n",
    "    p_weighted[k] /= total\n",
    "\n",
    "X_joint = history\n",
    "w_prior = np.array(list(p_weighted.values()))\n",
    "w_post = w_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(list(grouped_samples.keys()))):\n",
    "    key = list(grouped_samples.keys())[i]\n",
    "\n",
    "    p_weighted = defaultdict(float)\n",
    "    history = np.array(grouped_samples[key])\n",
    "    if history.shape[0]<30:\n",
    "        continue\n",
    "\n",
    "    distances = fast_dtw_distance(normal_seed, history)\n",
    "    weights = 1/distances**2\n",
    "    total = sum(weights)\n",
    "    weights /= total\n",
    "    X_marginal_obs = history\n",
    "    w_obs = weights\n",
    "    w_post = compute_posterior_weights_from_partial_subseq(\n",
    "        X_joint, w_post,\n",
    "        X_marginal_obs, w_obs,\n",
    "        bandwidth=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始資料與權重\n",
    "X = X_joint\n",
    "weights = w_post\n",
    "weights = weights / np.sum(weights)  # normalize\n",
    "\n",
    "# 建立 KDE 分布\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.5)  # bandwidth 可調整\n",
    "kde.fit(X, sample_weight=weights)\n",
    "\n",
    "# 生成新的資料\n",
    "new_samples = kde.sample(n_samples=100, random_state=42)\n",
    "new_samples = new_samples*std_seed + mean_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/Raw_Data/Gogoro/台北市大安區_臺大二活停車場站A ({:02d}).csv'.format(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batt_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-28 03:17:16</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 03:37:16</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 03:47:16</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 04:07:16</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 04:17:16</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04 17:39:03</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04 17:39:03</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04 18:40:24</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04 18:40:24</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04 18:40:24</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>846 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     batt_num\n",
       "time                         \n",
       "2023-12-28 03:17:16        24\n",
       "2023-12-28 03:37:16        24\n",
       "2023-12-28 03:47:16        24\n",
       "2023-12-28 04:07:16        24\n",
       "2023-12-28 04:17:16        24\n",
       "...                       ...\n",
       "2023-01-04 17:39:03        30\n",
       "2023-01-04 17:39:03        30\n",
       "2023-01-04 18:40:24        22\n",
       "2023-01-04 18:40:24        22\n",
       "2023-01-04 18:40:24        22\n",
       "\n",
       "[846 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(path, index_col=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiv2b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
