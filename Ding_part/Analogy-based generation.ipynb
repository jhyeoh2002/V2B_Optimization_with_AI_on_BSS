{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "from dtaidistance import dtw\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_index(timeend: np.datetime64, window_size: int) -> pd.DatetimeIndex:\n",
    "    freq = '10min'\n",
    "    return pd.date_range(end=timeend, periods=window_size, freq=freq)\n",
    "\n",
    "def safe_nansum(arr, axis=None):\n",
    "    result = np.nansum(arr, axis=axis)\n",
    "    # 判斷原始陣列沿 axis 全部是 NaN 的位置\n",
    "    all_nan = np.isnan(arr).all(axis=axis)\n",
    "    \n",
    "    # 將那些位置改為 np.nan\n",
    "    if np.isscalar(result):\n",
    "        return np.nan if all_nan else result\n",
    "    result = result.astype('float64')  # 確保能裝 NaN\n",
    "    result[all_nan] = np.nan\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tdf = pd.DataFrame()\n",
    "for i in range(0,40):\n",
    "    try:\n",
    "        df = pd.read_csv(f'../data/Raw_Data/Gogoro/台北市大安區_臺大二活停車場站A ({i:02d}).csv',index_col=0)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df.index = df.index.floor('min')\n",
    "        df = df[~df.index.duplicated()]\n",
    "        a_tdf = pd.concat([a_tdf,df])\n",
    "    except:\n",
    "        continue\n",
    "a_tdf = a_tdf[~a_tdf.index.duplicated()]\n",
    "a_tdf.sort_index(inplace=True)\n",
    "\n",
    "b_tdf = pd.DataFrame()\n",
    "for i in range(0,37):\n",
    "    try:\n",
    "        df = pd.read_csv(f'../data/Raw_Data/Gogoro/台北市大安區_臺大二活停車場站B ({i:02d}).csv',index_col=0)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df.index = df.index.floor('min')\n",
    "        df = df[~df.index.duplicated()]\n",
    "        b_tdf = pd.concat([b_tdf,df])\n",
    "    except:\n",
    "        continue\n",
    "b_tdf = b_tdf[~b_tdf.index.duplicated()]\n",
    "b_tdf.sort_index(inplace=True)\n",
    "\n",
    "tdf = pd.concat([a_tdf,b_tdf],axis=1).dropna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假設 df 已經處理好 index 是 datetime 且只保留到分鐘\n",
    "start = tdf.index.min()\n",
    "end = tdf.index.max()\n",
    "\n",
    "# 產生每分鐘的完整時間序列\n",
    "full_index = pd.date_range(start=start, end=end, freq='1min')\n",
    "\n",
    "# 將原始 df 補上缺的時間，空值保持為 NaN\n",
    "tdf_filled = tdf.reindex(full_index)\n",
    "\n",
    "tdf_filled = tdf_filled.resample('h').mean()\n",
    "tdf_filled.name = 'raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_valid_subsequences(arr, min_len=1, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = len(arr)\n",
    "\n",
    "    subsequences = []\n",
    "    N = len(arr)\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(i + min_len, min(i + max_len, N) + 1):\n",
    "            subseq = arr[i:j]\n",
    "            if not np.isnan(subseq[0]) and not np.isnan(subseq[-1]):\n",
    "                subsequences.append(subseq)\n",
    "    \n",
    "    return subsequences\n",
    "\n",
    "# 範例資料\n",
    "arr = tdf_filled.values\n",
    "\n",
    "window_size = 24\n",
    "samples = generate_valid_subsequences(arr, min_len=2, max_len=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "non_seen_list = []\n",
    "seen_in_group = defaultdict(set)  # 用來記錄每個 key 下已出現的 trimmed（tuple 形式）\n",
    "\n",
    "for i,row in enumerate(samples):\n",
    "    not_nan_indices = np.where(~np.isnan(row))[0]\n",
    "    if len(not_nan_indices) == 0:\n",
    "        continue  # 跳過全 NaN 的 row\n",
    "\n",
    "    # 去掉頭尾 NaN\n",
    "    start = not_nan_indices[0]\n",
    "    end = not_nan_indices[-1] + 1\n",
    "    trimmed = row[start:end]\n",
    "\n",
    "    # 觀測的位置（相對於 trimmed）\n",
    "    observed = tuple(np.where(~np.isnan(trimmed))[0])\n",
    "\n",
    "    # 把 trimmed 轉成 hashable 的 tuple 來比對是否出現過\n",
    "    trimmed_key = tuple(trimmed)\n",
    "\n",
    "    if trimmed_key not in seen_in_group[observed]:\n",
    "        non_seen_list.append(trimmed)\n",
    "        seen_in_group[observed].add(trimmed_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_samples = defaultdict(list)\n",
    "\n",
    "for i,row in enumerate(non_seen_list):\n",
    "    row[row<0] = np.nan\n",
    "    not_nan_indices = np.where(~np.isnan(row))[0]\n",
    "    if len(not_nan_indices) == 0:\n",
    "        continue  # 跳過全 NaN 的 row\n",
    "    \n",
    "    # 去掉頭尾 NaN\n",
    "    start = not_nan_indices[0]\n",
    "    end = not_nan_indices[-1] + 1\n",
    "    trimmed = row[start:end]\n",
    "    # 觀測的位置（相對於 trimmed）\n",
    "    observed = tuple(np.where(~np.isnan(trimmed))[0])\n",
    "    grouped_samples[observed].append(trimmed)\n",
    "    \n",
    "sorted_items = sorted(grouped_samples.items(), key=lambda x: len(x[0]), reverse=True)\n",
    "grouped_samples = dict(sorted_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.normal(loc=0, scale=1, size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "grouped_samples_copy = defaultdict(list)\n",
    "\n",
    "# 主迴圈\n",
    "while grouped_samples:\n",
    "    print(f\"剩餘群組數：{len(grouped_samples)}, 最長序列長度: {len(list(grouped_samples.keys())[0])}\")\n",
    "\n",
    "    # 取第一個 key（不需轉成 list）\n",
    "    current_key = next(iter(grouped_samples))\n",
    "    current_group = grouped_samples[current_key]\n",
    "\n",
    "    # 若樣本數夠多，移到 copy，並移除原 key\n",
    "    if len(current_group) > 30:\n",
    "        grouped_samples_copy[current_key] = current_group\n",
    "        del grouped_samples[current_key]\n",
    "        continue\n",
    "\n",
    "    # 不夠多，進行單點擴增\n",
    "    all_versions = []\n",
    "    for arr in current_group:\n",
    "        valid_indices = np.where(~np.isnan(arr))[0]\n",
    "        for idx in valid_indices:\n",
    "            arr_copy = arr.copy()\n",
    "            arr_copy[idx] = np.nan\n",
    "            all_versions.append(arr_copy)\n",
    "\n",
    "    # 重新分群\n",
    "    for row in all_versions:\n",
    "        observed = tuple(np.where(~np.isnan(row))[0])\n",
    "        grouped_samples.setdefault(observed, []).append(row)\n",
    "\n",
    "    # 移除已處理的 key\n",
    "    del grouped_samples[current_key]\n",
    "\n",
    "    # 可選：排序 key（但不轉成普通 dict）\n",
    "    grouped_samples = defaultdict(\n",
    "        list,\n",
    "        dict(sorted(grouped_samples.items(), key=lambda x: len(x[0]), reverse=True))\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_dtw_distance(ref, compare_arr):\n",
    "    if len(compare_arr.shape) == 2:\n",
    "        distances = np.empty(compare_arr.shape[0])\n",
    "        for i in range(compare_arr.shape[0]):\n",
    "            mask = ~np.isnan(compare_arr[i])\n",
    "            distances[i] = dtw.distance(ref[mask], compare_arr[i][mask])\n",
    "    else:\n",
    "        mask = ~np.isnan(compare_arr)\n",
    "        distances = dtw.distance(ref[mask], compare_arr[mask])\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406, 24)\n",
      "(426, 23)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along axis 0; size of axis is 24 but size of corresponding boolean axis is 23",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(pd.DataFrame(history).dropna(axis=\u001b[32m1\u001b[39m).shape)\n\u001b[32m     11\u001b[39m tmp.append(history.shape[\u001b[32m0\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m distances = \u001b[43mfast_dtw_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# weights = 1/distances**2\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# for row, weight in zip(history, weights):\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#     key = tuple(row[~np.isnan(row)])  # 觀測的變數組合\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# for k in p_weighted:\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#     p_weighted[k] /= total\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mfast_dtw_distance\u001b[39m\u001b[34m(ref, compare_arr)\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(compare_arr.shape[\u001b[32m0\u001b[39m]):\n\u001b[32m      5\u001b[39m         mask = ~np.isnan(compare_arr[i])\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         distances[i] = dtw.distance(\u001b[43mref\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m, compare_arr[i][mask])\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m      8\u001b[39m     mask = ~np.isnan(compare_arr)\n",
      "\u001b[31mIndexError\u001b[39m: boolean index did not match indexed array along axis 0; size of axis is 24 but size of corresponding boolean axis is 23"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in range(len(list(grouped_samples.keys()))):\n",
    "    key = list(grouped_samples.keys())[i]\n",
    "\n",
    "    p_weighted = defaultdict(float)\n",
    "    history = np.array(grouped_samples[key])\n",
    "\n",
    "    print(pd.DataFrame(history).dropna(axis=1).shape)\n",
    "    \n",
    "\n",
    "    tmp.append(history.shape[0])\n",
    "    distances = fast_dtw_distance(seed, history)\n",
    "    # weights = 1/distances**2\n",
    "    # for row, weight in zip(history, weights):\n",
    "    #     key = tuple(row[~np.isnan(row)])  # 觀測的變數組合\n",
    "    #     p_weighted[key] += weight\n",
    "    # total = sum(p_weighted.values())\n",
    "    # for k in p_weighted:\n",
    "    #     p_weighted[k] /= total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
       "          12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,\n",
       "          23,   24,   25,   26,   27,   28,   29,   30,   31,   32,   33,\n",
       "          34,   35,   36,   37,   38,   39,   40,   41,   42,   43,   44,\n",
       "          45,   46,   48,   49,   50,   52,   53,   54,   55,   56,   58,\n",
       "          59,   61,   62,   63,   64,   65,   66,   67,   69,   70,   71,\n",
       "          75,   76,   79,   80,   84,   88,   90,   95,   99,  101,  106,\n",
       "         110,  119,  137,  138,  202,  406,  426,  448,  472,  497,  525,\n",
       "         555,  590,  630,  676,  728,  782,  841,  903,  968, 1042, 1128,\n",
       "        1224, 1331, 1412, 1451, 1588, 1716]),\n",
       " array([6726,  731,  314,  239,  142,   48,   41,   22,   12,    9,    9,\n",
       "           7,    4,   12,    7,   11,   13,   13,    8,   21,    9,   12,\n",
       "           7,   10,    7,    8,    6,    7,    6,    4,    9,    3,    3,\n",
       "           8,    6,    3,    5,    4,    2,    5,    4,    1,    2,    5,\n",
       "           2,    2,    5,    3,    2,    1,    3,    2,    2,    1,    1,\n",
       "           3,    1,    2,    1,    1,    1,    1,    1,    1,    2,    1,\n",
       "           1,    1,    2,    1,    2,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tmp,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 模擬四組樣本\n",
    "# 先驗：完整四維樣本（40筆）\n",
    "prior_samples = pd.DataFrame(np.random.randint(0, 2, size=(40, 4)), columns=[\"x1\", \"x2\", \"x3\", \"x4\"])\n",
    "\n",
    "# 觀測一：p(x1,x2,x3) (100筆)\n",
    "obs_123 = pd.DataFrame(np.random.randint(0, 2, size=(100, 3)), columns=[\"x1\", \"x2\", \"x3\"])\n",
    "\n",
    "# 觀測二：p(x2,x3,x4) (80筆)\n",
    "obs_234 = pd.DataFrame(np.random.randint(0, 2, size=(80, 3)), columns=[\"x2\", \"x3\", \"x4\"])\n",
    "\n",
    "# 觀測三：p(x1,x3,x4) (60筆)\n",
    "obs_134 = pd.DataFrame(np.random.randint(0, 2, size=(60, 3)), columns=[\"x1\", \"x3\", \"x4\"])\n",
    "\n",
    "# 統計出觀測分布（作為後驗修正依據）\n",
    "def empirical_prob(samples, cols):\n",
    "    count = Counter([tuple(row) for row in samples[cols].values])\n",
    "    total = sum(count.values())\n",
    "    return {k: v / total for k, v in count.items()}\n",
    "\n",
    "p_obs_123 = empirical_prob(obs_123, [\"x1\", \"x2\", \"x3\"])\n",
    "p_obs_234 = empirical_prob(obs_234, [\"x2\", \"x3\", \"x4\"])\n",
    "p_obs_134 = empirical_prob(obs_134, [\"x1\", \"x3\", \"x4\"])\n",
    "\n",
    "# 初始樣本統計分布（先驗）\n",
    "prior_list = [tuple(row) for row in prior_samples[[\"x1\", \"x2\", \"x3\", \"x4\"]].values]\n",
    "\n",
    "# 先驗邊際（p123）\n",
    "prior_123 = Counter([(x1, x2, x3) for (x1, x2, x3, x4) in prior_list])\n",
    "prior_234 = Counter([(x2, x3, x4) for (x1, x2, x3, x4) in prior_list])\n",
    "prior_134 = Counter([(x1, x3, x4) for (x1, x2, x3, x4) in prior_list])\n",
    "total_prior = len(prior_list)\n",
    "\n",
    "# 對每一筆樣本做連乘權重更新（依序套用三次貝氏加權）\n",
    "weights = []\n",
    "for sample in prior_list:\n",
    "    x1, x2, x3, x4 = sample\n",
    "\n",
    "    # 取得對應子分布機率\n",
    "    p1 = p_obs_123.get((x1, x2, x3), 1e-6) / (prior_123.get((x1, x2, x3), 1e-6) / total_prior)\n",
    "    p2 = p_obs_234.get((x2, x3, x4), 1e-6) / (prior_234.get((x2, x3, x4), 1e-6) / total_prior)\n",
    "    p3 = p_obs_134.get((x1, x3, x4), 1e-6) / (prior_134.get((x1, x3, x4), 1e-6) / total_prior)\n",
    "\n",
    "    weights.append(p1 * p2 * p3)\n",
    "\n",
    "# 權重正規化\n",
    "weights = np.array(weights)\n",
    "weights /= weights.sum()\n",
    "\n",
    "# 統計後驗分布\n",
    "posterior = {}\n",
    "for i, sample in enumerate(prior_list):\n",
    "    posterior[sample] = posterior.get(sample, 0) + weights[i]\n",
    "\n",
    "# 整理為 DataFrame\n",
    "df_post = pd.DataFrame([(*k, v) for k, v in posterior.items()], columns=[\"x1\", \"x2\", \"x3\", \"x4\", \"prob\"])\n",
    "df_post = df_post.sort_values(\"prob\", ascending=False).reset_index(drop=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiv2b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
