nohup: ignoring input
Crash diagnostics ON


==================================================
PART 1: Data preprocess for 2023-01-01 00:00:00 to 2024-09-30 23:00:00...
==================================================

	1.1 Preprocessing radiation data...
		[INFO] Radiation data already exists at './data/timeseries/radiation_data.csv'

	1.2 Preprocessing temperature data...
		[INFO] Temperature data already exists at './data/timeseries/temperature_data.csv'

	1.3 Preprocessing building data...
		[INFO] Building data already exists at './data/timeseries/building_data.csv'

	1.4 Preprocessing electricity cost data...
		[INFO] Electricity cost data already exists at './data/timeseries/electricitycostG2B_data.csv' and './data/timeseries/electricitycostG2V_data.csv'

	1.5 Preprocessing battery demand series data...
		[INFO] Found existing battery data at 'data/battery_demand/resample_full.csv' and 'data/battery_demand/resample_train.csv'

		[INFO] Number of series for clean windows = (110, 49)
		[INFO] Number of eligible series for Case 2 = (1373, 49)
		[INFO] Case 1 exists â€” loaded battery demand from 'data/battery_demand/case1_real_only/battery_demand.npy' with shape (168, 37).
		[INFO] Case 2 exists â€” loaded battery demand from 'data/battery_demand/case2_nan_filled/battery_demand.npy' with shape (1563, 37).
		[INFO] Case 0: Successfully added test pair 2024-03-15 & 2024-03-16
		Data: [10536, 28, 30, 35, 37, 37, 36, 33, 26, 10, 6, 10, 14, 19, 18, 15, 20, 26, 15, 9, 16, 21, 20, 8, 12, 15, 24, 31, 35, 32, 35, 34, 32, 31, 30, 22, 14, 18, 27, 18, 19, 19, 25, 25, 25, 26, 27, 17, 19]
		[INFO] Case 0: Successfully added test pair 2024-03-29 & 2024-03-30
		Data: [10872, 13, 26, 31, 33, 33, 33, 31, 15, 8, 19, 11, 15, 18, 16, 18, 18, 19, 7, 4, 23, 23, 16, 17, 18, 18, 19, 24, 29, 30, 30, 22, 27, 21, 14, 15, 16, 20, 18, 23, 27, 18, 2, 10, 23, 22, 22, 17, 21]

	1.6 Generating battery schedule...
		[INFO] Case 1 exists â€” loaded from 'data/battery_demand/case1_real_only/battery_availability.npy' and 'data/battery_demand/case1_real_only/battery_details.npy' shape (168, 385, 36) and (4, 168, 385)
		[INFO] Case 2 exists â€” loaded from 'data/battery_demand/case2_nan_filled/battery_availability.npy' and 'data/battery_demand/case2_nan_filled/battery_details.npy' shape (1563, 385, 36) and (4, 1563, 385)
[ERROR] Could not load battery demand from 'data/battery_demand/case3_extended_generated/battery_demand.npy': [Errno 2] No such file or directory: 'data/battery_demand/case3_extended_generated/battery_demand.npy'


==================================================
PART 2: MILP Optimization...
==================================================

	2.2 Optimizing Case 2...
		[INFO] Loaded 1563 samples from 'data/battery_demand/case2_nan_filled'
		[INFO] Results already exist at './data/optimization_results/case2_nan_filled/immediate_charging/V2B.npy'. Skipping immediate_charging run.
		[INFO] Results already exist at './data/optimization_results/case2_nan_filled/optimization/V2B.npy'. Skipping optimization run.
		[INFO] Case 2 completed.

	2.1 Optimizing Case 1...
		[INFO] Loaded 168 samples from 'data/battery_demand/case1_real_only'
		[INFO] Results already exist at './data/optimization_results/case1_real_only/immediate_charging/V2B.npy'. Skipping immediate_charging run.
		[INFO] Results already exist at './data/optimization_results/case1_real_only/optimization/V2B.npy'. Skipping optimization run.
		[INFO] Case 1 completed.


==================================================
PART 3: Supervised Learning...
==================================================

	3.2 Training Case 2...

=== Starting Training Run: STAFV4_CASE2 ===
Device: cuda
		[INFO] Starting Preprocessing for Case 2...
		[INFO] Unique quantized indices: 28274
		[INFO] Suggested num_embeddings: 33928
		[INFO] Generating sliding windows...
		[INFO] Saved dataset: ./data/training_results/STAFV4_CASE2/merged_dataset_STAFV4_CASE2.csv (Shape: (18756, 201))
		[INFO] Saved metadata: ./data/training_results/STAFV4_CASE2/feature_info_STAFV4_CASE2.json
	[Model Config] Detected Dims: {'static': 4, 'series_count': 5, 'seq_len': 24, 'vehicle': 76, 'emb_vocab': 33928}
		[INFO] Data loaded. Train: 13129, Val: 5627
		[INFO] Fitting new scalers on training data...
		[INFO] 
==================================================
		[INFO] ðŸš€ TRAINING SESSION: STAFV4_CASE2
		[INFO] ==================================================
		[INFO] Device:             cuda
		[INFO] Model Parameters:   1,159,026
		[INFO] --------------------------------------------------
		[INFO] Epochs:             5000
		[INFO] Batch Size:         128
		[INFO] Learning Rate:      0.001
		[INFO] Weight Decay:       0.001
		[INFO] Dropout:            0.5
		[INFO] --------------------------------------------------
		[INFO] Hidden Layers:      [256, 64, 64]
		[INFO] Embedding Dim:      32
		[INFO] Attention Heads:    4
		[INFO]==================================================


		[INFO]Epoch |    LR    | Trn RMSE | Val RMSE | Trn R2 | Val R2 | Stop
-----------------------------------------------------------------
		[INFO]    1 | 0.001000 |   9.9753 |   8.2936 | -0.907 | -0.314 | 0/150
		[INFO]    2 | 0.001000 |   6.9825 |   5.3539 |  0.066 |  0.453 | 0/150
		[INFO]    3 | 0.001000 |   5.1451 |   4.3209 |  0.493 |  0.643 | 0/150
		[INFO]    4 | 0.001000 |   4.5671 |   3.9939 |  0.601 |  0.695 | 0/150
		[INFO]    5 | 0.001000 |   4.3064 |   3.8653 |  0.645 |  0.715 | 0/150
		[INFO]    6 | 0.001000 |   4.1785 |   3.7830 |  0.667 |  0.727 | 0/150
		[INFO]    7 | 0.001000 |   4.0216 |   3.7548 |  0.691 |  0.731 | 0/150
		[INFO]    8 | 0.001000 |   3.9323 |   3.7073 |  0.704 |  0.737 | 0/150
		[INFO]    9 | 0.001000 |   3.8694 |   3.6638 |  0.714 |  0.744 | 0/150
		[INFO]   10 | 0.001000 |   3.7950 |   3.5989 |  0.724 |  0.753 | 0/150
		[INFO]   11 | 0.001000 |   3.6645 |   3.5758 |  0.743 |  0.756 | 0/150
		[INFO]   12 | 0.001000 |   3.6681 |   3.5885 |  0.742 |  0.754 | 0/150
		[INFO]   13 | 0.001000 |   3.5919 |   3.5959 |  0.753 |  0.753 | 1/150
		[INFO]   14 | 0.001000 |   3.5132 |   3.5898 |  0.764 |  0.754 | 2/150
		[INFO]   15 | 0.001000 |   3.4883 |   3.5930 |  0.767 |  0.753 | 3/150
		[INFO]   16 | 0.001000 |   3.4202 |   3.5971 |  0.776 |  0.753 | 4/150
		[INFO]   17 | 0.001000 |   3.3709 |   3.5810 |  0.783 |  0.755 | 5/150
		[INFO]   18 | 0.001000 |   3.2933 |   3.5974 |  0.793 |  0.753 | 6/150
		[INFO]   19 | 0.001000 |   3.2793 |   3.6340 |  0.794 |  0.748 | 7/150
		[INFO]   20 | 0.001000 |   3.2521 |   3.6029 |  0.797 |  0.752 | 8/150
		[INFO]   21 | 0.001000 |   3.1882 |   3.6132 |  0.805 |  0.751 | 9/150
		[INFO]   22 | 0.001000 |   3.1534 |   3.6496 |  0.810 |  0.746 | 10/150
		[INFO]   23 | 0.001000 |   3.1374 |   3.6420 |  0.812 |  0.747 | 11/150
		[INFO]   24 | 0.001000 |   3.0970 |   3.6367 |  0.816 |  0.747 | 12/150
		[INFO]   25 | 0.001000 |   3.0664 |   3.6600 |  0.820 |  0.744 | 13/150
		[INFO]   26 | 0.001000 |   3.0458 |   3.7426 |  0.823 |  0.732 | 14/150
		[INFO]   27 | 0.001000 |   3.0587 |   3.6699 |  0.821 |  0.743 | 15/150
		[INFO]   28 | 0.001000 |   2.9855 |   3.7180 |  0.829 |  0.736 | 16/150
		[INFO]   29 | 0.001000 |   2.9657 |   3.7215 |  0.832 |  0.735 | 17/150
		[INFO]   30 | 0.001000 |   2.9557 |   3.7799 |  0.833 |  0.727 | 18/150
		[INFO]   31 | 0.001000 |   2.9255 |   3.7479 |  0.836 |  0.732 | 19/150
		[INFO]   32 | 0.001000 |   2.9071 |   3.7394 |  0.838 |  0.733 | 20/150
		[INFO]   33 | 0.001000 |   2.8336 |   3.7715 |  0.846 |  0.728 | 21/150
		[INFO]   34 | 0.001000 |   2.8559 |   3.7666 |  0.844 |  0.729 | 22/150
		[INFO]   35 | 0.001000 |   2.8369 |   3.8247 |  0.846 |  0.721 | 23/150
		[INFO]   36 | 0.001000 |   2.8406 |   3.7688 |  0.845 |  0.729 | 24/150
		[INFO]   37 | 0.001000 |   2.8031 |   3.8031 |  0.850 |  0.724 | 25/150
		[INFO]   38 | 0.000750 |   2.7649 |   3.8301 |  0.854 |  0.720 | 26/150
		[INFO]   39 | 0.000750 |   2.7498 |   3.7894 |  0.855 |  0.726 | 27/150
		[INFO]   40 | 0.000750 |   2.7190 |   3.7789 |  0.859 |  0.727 | 28/150
		[INFO]   41 | 0.000750 |   2.7543 |   3.8439 |  0.855 |  0.718 | 29/150
		[INFO]   42 | 0.000750 |   2.7022 |   3.8322 |  0.860 |  0.719 | 30/150
		[INFO]   43 | 0.000750 |   2.7026 |   3.8622 |  0.860 |  0.715 | 31/150
		[INFO]   44 | 0.000750 |   2.6728 |   3.8445 |  0.863 |  0.718 | 32/150
		[INFO]   45 | 0.000750 |   2.6804 |   3.8380 |  0.863 |  0.719 | 33/150
		[INFO]   46 | 0.000750 |   2.6637 |   3.8504 |  0.864 |  0.717 | 34/150
		[INFO]   47 | 0.000750 |   2.6402 |   3.8457 |  0.867 |  0.718 | 35/150
		[INFO]   48 | 0.000750 |   2.6332 |   3.8613 |  0.867 |  0.715 | 36/150
		[INFO]   49 | 0.000750 |   2.5952 |   3.9159 |  0.871 |  0.707 | 37/150
		[INFO]   50 | 0.000750 |   2.5950 |   3.9115 |  0.871 |  0.708 | 38/150
		[INFO]   51 | 0.000750 |   2.5908 |   3.8996 |  0.872 |  0.710 | 39/150
		[INFO]   52 | 0.000750 |   2.5962 |   3.8615 |  0.871 |  0.715 | 40/150
		[INFO]   53 | 0.000750 |   2.5826 |   3.9147 |  0.873 |  0.707 | 41/150
		[INFO]   54 | 0.000750 |   2.5860 |   3.8986 |  0.872 |  0.710 | 42/150
		[INFO]   55 | 0.000750 |   2.5590 |   3.8913 |  0.875 |  0.711 | 43/150
		[INFO]   56 | 0.000750 |   2.6030 |   3.9134 |  0.870 |  0.707 | 44/150
		[INFO]   57 | 0.000750 |   2.5602 |   3.9103 |  0.875 |  0.708 | 45/150
		[INFO]   58 | 0.000750 |   2.5812 |   3.9413 |  0.873 |  0.703 | 46/150
		[INFO]   59 | 0.000750 |   2.5351 |   3.9346 |  0.877 |  0.704 | 47/150
		[INFO]   60 | 0.000750 |   2.5554 |   3.9060 |  0.876 |  0.709 | 48/150
		[INFO]   61 | 0.000750 |   2.5255 |   3.9210 |  0.878 |  0.706 | 49/150
		[INFO]   62 | 0.000750 |   2.4989 |   3.9357 |  0.881 |  0.704 | 50/150
		[INFO]   63 | 0.000750 |   2.5118 |   3.9689 |  0.879 |  0.699 | 51/150
		[INFO]   64 | 0.000563 |   2.5354 |   3.9399 |  0.877 |  0.704 | 52/150
		[INFO]   65 | 0.000563 |   2.5021 |   3.9587 |  0.880 |  0.701 | 53/150
		[INFO]   66 | 0.000563 |   2.4345 |   3.9441 |  0.887 |  0.703 | 54/150
		[INFO]   67 | 0.000563 |   2.5246 |   4.0117 |  0.878 |  0.693 | 55/150
		[INFO]   68 | 0.000563 |   2.4591 |   3.9707 |  0.884 |  0.699 | 56/150
		[INFO]   69 | 0.000563 |   2.4350 |   3.9655 |  0.886 |  0.700 | 57/150
		[INFO]   70 | 0.000563 |   2.4124 |   3.9544 |  0.889 |  0.701 | 58/150
		[INFO]   71 | 0.000563 |   2.4477 |   4.0056 |  0.886 |  0.694 | 59/150
		[INFO]   72 | 0.000563 |   2.4273 |   3.9730 |  0.887 |  0.699 | 60/150
		[INFO]   73 | 0.000563 |   2.4049 |   3.9943 |  0.889 |  0.695 | 61/150
		[INFO]   74 | 0.000563 |   2.4002 |   4.0152 |  0.890 |  0.692 | 62/150
		[INFO]   75 | 0.000563 |   2.3921 |   3.9693 |  0.891 |  0.699 | 63/150
		[INFO]   76 | 0.000563 |   2.4431 |   3.9943 |  0.886 |  0.695 | 64/150
		[INFO]   77 | 0.000563 |   2.4240 |   3.9599 |  0.888 |  0.701 | 65/150
		[INFO]   78 | 0.000563 |   2.4025 |   3.9637 |  0.890 |  0.700 | 66/150
		[INFO]   79 | 0.000563 |   2.3704 |   3.9879 |  0.892 |  0.696 | 67/150
		[INFO]   80 | 0.000563 |   2.4142 |   4.0064 |  0.889 |  0.693 | 68/150
		[INFO]   81 | 0.000563 |   2.3989 |   3.9706 |  0.890 |  0.699 | 69/150
		[INFO]   82 | 0.000563 |   2.4135 |   3.9798 |  0.889 |  0.697 | 70/150
		[INFO]   83 | 0.000563 |   2.4244 |   4.0053 |  0.888 |  0.694 | 71/150
		[INFO]   84 | 0.000563 |   2.3498 |   3.9659 |  0.894 |  0.700 | 72/150
		[INFO]   85 | 0.000563 |   2.3402 |   4.0392 |  0.895 |  0.688 | 73/150
		[INFO]   86 | 0.000563 |   2.3738 |   3.9809 |  0.892 |  0.697 | 74/150
		[INFO]   87 | 0.000563 |   2.3547 |   3.9895 |  0.894 |  0.696 | 75/150
		[INFO]   88 | 0.000563 |   2.3395 |   3.9922 |  0.895 |  0.696 | 76/150
		[INFO]   89 | 0.000563 |   2.3102 |   4.0154 |  0.898 |  0.692 | 77/150
		[INFO]   90 | 0.000422 |   2.3137 |   3.9837 |  0.898 |  0.697 | 78/150
		[INFO]   91 | 0.000422 |   2.3372 |   4.0247 |  0.895 |  0.691 | 79/150
		[INFO]   92 | 0.000422 |   2.3174 |   4.0028 |  0.897 |  0.694 | 80/150
		[INFO]   93 | 0.000422 |   2.2959 |   4.0172 |  0.899 |  0.692 | 81/150
		[INFO]   94 | 0.000422 |   2.3261 |   3.9890 |  0.897 |  0.696 | 82/150
		[INFO]   95 | 0.000422 |   2.3263 |   3.9921 |  0.896 |  0.696 | 83/150
