/home/lisa4090/Documents/GitHub/V2B_Optimization_with_AI_on_BSS/supervised_learning/dataloader/preprocess.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill")
/home/lisa4090/Documents/GitHub/V2B_Optimization_with_AI_on_BSS/supervised_learning/dataloader/preprocess.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill")
/home/lisa4090/Documents/GitHub/V2B_Optimization_with_AI_on_BSS/supervised_learning/dataloader/preprocess.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill")
/home/lisa4090/Documents/GitHub/V2B_Optimization_with_AI_on_BSS/supervised_learning/dataloader/preprocess.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill")
/home/lisa4090/anaconda3/envs/AIonBSS/lib/python3.13/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Crash diagnostics ON


==================================================
PART 1: Data preprocess for 2023-01-01 00:00:00 to 2024-09-30 23:00:00...
==================================================

	1.1 Preprocessing radiation data...
		[INFO] Radiation data already exists at './data/timeseries/radiation_data.csv'

	1.2 Preprocessing temperature data...
		[INFO] Temperature data already exists at './data/timeseries/temperature_data.csv'

	1.3 Preprocessing building data...
		[INFO] Building data already exists at './data/timeseries/building_data.csv'

	1.4 Preprocessing electricity cost data...
		[INFO] Electricity cost data already exists at './data/timeseries/electricitycostG2B_data.csv' and './data/timeseries/electricitycostG2V_data.csv'

	1.5 Preprocessing battery demand series data...
		[INFO] Found existing battery data at './data/battery_demand/tol25/resample_full.csv' and './data/battery_demand/tol25/resample_train.csv'

		[INFO] Number of series for clean windows = (168, 37)
		[INFO] Number of eligible series for Case 2 = (1377, 37)
		[INFO] Number of seeds ready for Case 3  = (2000, 36)

		[INFO] Case 1 exists â€” loaded battery demand from './data/battery_demand/tol25/case1_real_only/battery_demand.npy' with shape (168, 37).
		[INFO] Case 2 exists â€” loaded battery demand from './data/battery_demand/tol25/case2_nan_filled/battery_demand.npy' with shape (1545, 37).
		[INFO] Case 3 exists â€” loaded battery demand from './data/battery_demand/tol25/case3_extended_generated/battery_demand.npy' with shape (3545, 37).

	1.6 Generating battery schedule...
		[INFO] Case 1 exists â€” loaded from './data/battery_demand/tol25/case1_real_only/battery_availability.npy' and './data/battery_demand/tol25/case1_real_only/battery_details.npy' shape (168, 263, 36) and (4, 168, 263)
		[INFO] Case 2 exists â€” loaded from './data/battery_demand/tol25/case2_nan_filled/battery_availability.npy' and './data/battery_demand/tol25/case2_nan_filled/battery_details.npy' shape (1545, 311, 36) and (4, 1545, 311)
		[INFO] Case 3 exists â€” loaded from './data/battery_demand/tol25/case3_extended_generated/battery_availability.npy' and './data/battery_demand/tol25/case3_extended_generated/battery_details.npy' shape (3545, 422, 36) and (4, 3545, 422)


==================================================
PART 2: MILP Optimization...
==================================================

	2.1 Optimizing Case 1...
		[INFO] Loaded 168 samples from './data/battery_demand/tol25/case1_real_only'
		[INFO] Results already exist at './data/optimization_results/tol25/case1_real_only/optimization/V2B.npy'. Skipping optimization run.
		[INFO] Results already exist at './data/optimization_results/tol25/case1_real_only/immediate_charging/V2B.npy'. Skipping immediate_charging run.
		[INFO] Case 1 completed.

	2.2 Optimizing Case 2...
		[INFO] Loaded 1545 samples from './data/battery_demand/tol25/case2_nan_filled'
		[INFO] Results already exist at './data/optimization_results/tol25/case2_nan_filled/optimization/V2B.npy'. Skipping optimization run.
		[INFO] Results already exist at './data/optimization_results/tol25/case2_nan_filled/immediate_charging/V2B.npy'. Skipping immediate_charging run.
		[INFO] Case 2 completed.

	2.3 Optimizing Case 3...
		[INFO] Loaded 3545 samples from './data/battery_demand/tol25/case3_extended_generated'
		[INFO] Results already exist at './data/optimization_results/tol25/case3_extended_generated/optimization/V2B.npy'. Skipping optimization run.
		[INFO] Results already exist at './data/optimization_results/tol25/case3_extended_generated/immediate_charging/V2B.npy'. Skipping immediate_charging run.
		[INFO] Case 3 completed.


==================================================
PART 3: Supervised Learning...
==================================================

	3.1 Training Case 1...
=== Training Log Started: 2025-11-27 20:59:40.121129 ===
Run Name: STAFV2_25_CASE1
Device: cuda
Data Source: ./data/training_results/merged_windowed_dataset_STAFV2_25_CASE1.csv
Feature Info: ./data/training_results/feature_info_STAFV2_25_CASE1.json
Output Directory: ./data/training_results/STAFV2_25_CASE1
Checkpoint Directory: ./data/training_results/STAFV2_25_CASE1/checkpoints
Plot Save Path: ./data/training_results/STAFV2_25_CASE1/trainingresults_plot.png
Epochs: 50000, Batch Size: 32, Learning Rate: 0.0001
LR Scheduler: Step Size = 100, Gamma = 0.8
============================================================
ðŸ”¢ Unique quantized indices: 6686
âœ… Suggested num_embeddings: 8023
âœ… Processed 168 valid samples.
âœ… Saved merged dataset: ./data/training_results/merged_windowed_dataset_STAFV2_25_CASE1.csv  (shape: (168, 429))
âœ… Saved feature metadata: ./data/training_results/feature_info_STAFV2_25_CASE1.json
âœ… Dataset split: 117 train, 51 val
âœ… Scalers fitted and saved.

âœ… Model initialized with 785956 trainable parameters.

TemporalAttentiveFusionNet(
  (seriesEmbedding): Embedding(8000, 64)
  (attn): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
  )
  (attn_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  (attn_fc): Linear(in_features=64, out_features=1, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
  (bn0): BatchNorm1d(433, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=433, out_features=512, bias=True)
  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=512, out_features=64, bias=True)
  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc4): Linear(in_features=64, out_features=1, bias=True)
  (relu): ReLU()
)
StepLR Scheduler: step_size = 100 , gamma = 0.8
============================================================
Starting training...

Epoch 1/50000:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 1/50000:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  2.50it/s]                                                            DEBUG Check - Step: 0
Traceback (most recent call last):
  File "/home/lisa4090/Documents/GitHub/V2B_Optimization_with_AI_on_BSS/main.py", line 65, in <module>
    main()
    ~~~~^^
  File "/home/lisa4090/Documents/GitHub/V2B_Optimization_with_AI_on_BSS/main.py", line 42, in main
    train(case_id=case_num, tolerance=target_tolerance)
    ~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lisa4090/Documents/GitHub/V2B_Optimization_with_AI_on_BSS/supervised_learning/training.py", line 152, in train
    print(f"train_labels shape: {train_labels.shape}, Has NaNs: {np.isnan(train_labels).any()}")
                                 ^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'shape'
